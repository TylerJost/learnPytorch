{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da098e8e",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "Basically a numpy array that is specialized for GPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892d3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd64989",
   "metadata": {},
   "source": [
    "## Making Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a51226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d005a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.9314, 0.9112],\n",
      "        [0.1374, 0.3319]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d015618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.6584, 0.4244, 0.3243],\n",
      "        [0.2817, 0.7060, 0.1529]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f47eda",
   "metadata": {},
   "source": [
    "## Tensor Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ed216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4bbd308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "  print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27e5dc1",
   "metadata": {},
   "source": [
    "Tensors are pretty similar to numpy arrays, so it really shouldn't be too big of a deal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5905d7",
   "metadata": {},
   "source": [
    "# Using `TORCH.AUTOGRAD`\n",
    "This is the automatic differentiation used for backprop in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08a345c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/08002/tjost/ls6/miniconda3/envs/computerVision/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/work/08002/tjost/ls6/miniconda3/envs/computerVision/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home1/08002/tjost/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30382f85d7ca494986de6cfe1d99c2e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "# Simulate an image with 3 channels, and a height/width of 64\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8365902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "prediction = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe7948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic loss\n",
    "loss = (prediction - labels).sum()\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7495ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimizer\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "# Initiate gradient descent\n",
    "optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47696c9c",
   "metadata": {},
   "source": [
    "### Autograd Details - Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89ae5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf9d28",
   "metadata": {},
   "source": [
    "Create a new tensor `Q` from `a` and `b`\n",
    "$$\n",
    "Q = 3a^3 - b^2\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eee1946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5f8fa",
   "metadata": {},
   "source": [
    "Find partial derivatives:\n",
    "$$\n",
    "\\frac{\\partial{Q}}{\\partial{a}} = 9a^2\n",
    "\\\\\n",
    "\\frac{\\partial{Q}}{\\partial{b}} = -2b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca7095",
   "metadata": {},
   "source": [
    "Calling `.backward()` on `Q` will calculate the gradients and store them in `.grad`\n",
    "\n",
    "From tutorial:\n",
    "\"We need to explicitly pass a gradient argument in Q `.backward()` because it is a vector. `gradient` is a tensor of the same shape as Q, and it represents the gradient of Q w.r.t. itself, i.e.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{Q}}{\\partial{Q}} = 1\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec0b914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ce436a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36., 81.])\n",
      "tensor([-12.,  -8.])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c25a55",
   "metadata": {},
   "source": [
    "Makes sense! Eg:\n",
    "$$\n",
    "\\frac{\\partial{Q}}{\\partial{a}} = 9a^2 = 9*4^2 = 36\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ae9df",
   "metadata": {},
   "source": [
    "We don't have to use autograd on everything. For example, we could finetune a pretrained network by \"freezing\" most of the model. Let's load and freeze a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbb9001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed3674",
   "metadata": {},
   "source": [
    "For this, the classifier is the last layer called `model.fc`. We can replace it with a new layer which is unfrozen by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a36a8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f7c0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize only the classifier\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
